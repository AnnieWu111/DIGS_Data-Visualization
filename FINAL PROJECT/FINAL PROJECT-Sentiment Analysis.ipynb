{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96c1040e-5d32-45e1-b527-3a5d28166bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output, State\n",
    "import nltk.downloader\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "#nltk.download('punkt_tab')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "651eaaf0-1dc5-4a61-bc18-168b3f3a8074",
   "metadata": {},
   "source": [
    "with open('chapter_45.txt', 'w', encoding='utf-8') as chap45:\n",
    "    for sentence in sentences:\n",
    "        chap45.write(sentence.strip() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf4bc07-fe0b-47fa-a38d-16ab87db6186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12004b8f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "SchemaLengthValidationError               Traceback (most recent call last)\n",
      "SchemaLengthValidationError: Schema: [<Output `summary-stats.children`>, <Output `word-freq-chart.figure`>, <Output `wordcloud-image.src`>, <Output `sentiment-gauge.figure`>, <Output `polarity-subjectivity.figure`>, <Output `pos-chart.figure`>, <Output `sentence-length.figure`>, <Output `complexity-chart.figure`>, <Output `negative-percent.children`>, <Output `neutral-percent.children`>, <Output `positive-percent.children`>]\n",
      "Path: ()\n",
      "Expected length: 11\n",
      "Received value of length 8:\n",
      "    [['No text to analyze'], {}, None, {}, {}, {}, {}, {}]\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "SchemaLengthValidationError               Traceback (most recent call last)\n",
      "SchemaLengthValidationError: Schema: [<Output `summary-stats.children`>, <Output `word-freq-chart.figure`>, <Output `wordcloud-image.src`>, <Output `sentiment-gauge.figure`>, <Output `polarity-subjectivity.figure`>, <Output `pos-chart.figure`>, <Output `sentence-length.figure`>, <Output `complexity-chart.figure`>, <Output `negative-percent.children`>, <Output `neutral-percent.children`>, <Output `positive-percent.children`>]\n",
      "Path: ()\n",
      "Expected length: 11\n",
      "Received value of length 8:\n",
      "    [['No text to analyze'], {}, None, {}, {}, {}, {}, {}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize the Dash app\n",
    "app = dash.Dash(__name__, title=\"Text Analysis\")\n",
    "\n",
    "#Define the layout\n",
    "block_style = {\n",
    "    'padding': 20,\n",
    "    'backgroundColor': '#f9f9f9',\n",
    "    'borderRadius': 10,\n",
    "    'marginBottom': 20,\n",
    "    'boxShadow': '0 2px 4px rgba(0,0,0,0.1)'\n",
    "}\n",
    "upload_style = {\n",
    "    'width': '100%',\n",
    "    'height': '60px',\n",
    "    'lineHeight': '60px',\n",
    "    'borderWidth': '1px',\n",
    "    'borderStyle': 'dashed',\n",
    "    'borderRadius': '5px',\n",
    "    'textAlign': 'center',\n",
    "    'margin': '10px 0',\n",
    "    'cursor': 'pointer'\n",
    "}\n",
    "\n",
    "#layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Text Analysis for Dream of the Red Chamber\", style={'textAlign': 'center', 'marginBottom': 30}),\n",
    "    \n",
    "    #text input\n",
    "    html.Div([\n",
    "        html.H3(\"text input\"),\n",
    "        \n",
    "        #file upload\n",
    "        dcc.Upload(\n",
    "            id='upload-data',\n",
    "            children=html.Div([\n",
    "                'choose txt.file to upload',\n",
    "                html.Small('(click here to upload)')\n",
    "            ]),\n",
    "            style=upload_style,\n",
    "            multiple=False,\n",
    "            accept='.txt'\n",
    "        ),\n",
    "        \n",
    "        dcc.Textarea(\n",
    "            id='text-input',\n",
    "            placeholder='...',\n",
    "            style={'width': '100%', 'height': 200, 'marginTop': 10},\n",
    "            value=''\n",
    "        ),\n",
    "        \n",
    "        #buttons\n",
    "        html.Div([\n",
    "            html.Button('Analyze', id='analyze-button', n_clicks=0, \n",
    "                       style={'marginRight': 10, 'backgroundColor': '#4CAF50', \n",
    "                              'color': 'white', 'border': 'none', 'padding': '10px 20px'}),\n",
    "            \n",
    "            html.Button('Download', id='download-button', n_clicks=0,\n",
    "                       style={'backgroundColor': '#2196F3', \n",
    "                              'color': 'white', 'border': 'none', 'padding': '10px 20px'}),\n",
    "            \n",
    "            dcc.Download(id=\"download-text\")\n",
    "        ], style={'marginTop': 10})\n",
    "    ], style=block_style),\n",
    "    \n",
    "    #Text Statistics Summary\n",
    "    html.Div([\n",
    "        html.H3(\"Statistics Summary\", style={'textAlign': 'center'}),\n",
    "        html.Div(id='summary-stats', style={'display': 'flex', \n",
    "                                          'justifyContent': 'space-around', \n",
    "                                          'flexWrap': 'wrap'})\n",
    "    ], style=block_style),\n",
    "    \n",
    "    #Word Frequency\n",
    "    html.Div([\n",
    "        html.H3(\"Top Words\", style={'textAlign': 'center'}),\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.H4(\"Top 15 Words by Frequency\"),\n",
    "                dcc.Graph(id='word-freq-chart')\n",
    "            ], style={'width': '60%', 'padding': 10}),\n",
    "            html.Div([\n",
    "                html.H4(\"Word Cloud\"),\n",
    "                html.Img(id='wordcloud-image', style={'width': '100%'})\n",
    "            ], style={'width': '40%', 'padding': 10})\n",
    "        ], style={'display': 'flex'})\n",
    "    ], style=block_style),\n",
    "    \n",
    "    #Sentiment Analysis\n",
    "    html.Div([\n",
    "        html.H3(\"Sentiment Analysis\", style={'textAlign': 'center'}),\n",
    "        \n",
    "        #sentiment percentage\n",
    "        html.Div([\n",
    "            html.H4(\"Sentiment in Percentage\", style={'textAlign': 'center', 'width': '100%'}),       \n",
    "            html.Div([ \n",
    "                      \n",
    "                 html.Div([ \n",
    "                    html.Div(\"negative\", style={\n",
    "                        'padding': 10,\n",
    "                        'backgroundColor': '#f0f0f0',\n",
    "                        'textAlign': 'center'\n",
    "                    }),\n",
    "                    html.Div(id='negative-percent', style={\n",
    "                        'fontSize': 24,\n",
    "                        'color': 'white',\n",
    "                        'backgroundColor': 'mediumpurple',\n",
    "                        'padding': 10,\n",
    "                        'borderRadius': '0 10px 10px 0',\n",
    "                        'textAlign': 'center'\n",
    "                    })\n",
    "                ], style={'width': '33%'}),\n",
    "                \n",
    "                html.Div([\n",
    "                    \n",
    "                    html.Div(\"neutral\", style={\n",
    "                        'padding': 10,\n",
    "                        'backgroundColor': '#f0f0f0',\n",
    "                        'textAlign': 'center'\n",
    "                    }),\n",
    "                    html.Div(id='neutral-percent', style={\n",
    "                        'fontSize': 24,\n",
    "                        'color': 'white',\n",
    "                        'backgroundColor': 'lightgray',\n",
    "                        'padding': 10,\n",
    "                        'textAlign': 'center'\n",
    "                    })\n",
    "                ], style={'width': '34%'}),\n",
    "                \n",
    "                html.Div([\n",
    "                    html.Div(\"positive\", style={\n",
    "                        'padding': 10,\n",
    "                        'backgroundColor': '#f0f0f0',\n",
    "                        'textAlign': 'center'\n",
    "                    }),\n",
    "                    html.Div(id='positive-percent', style={\n",
    "                        'fontSize': 24,\n",
    "                        'color': 'white',\n",
    "                        'backgroundColor': 'sandybrown',\n",
    "                        'padding': 10,\n",
    "                        'borderRadius': '10px 0 0 10px',\n",
    "                        'textAlign': 'center'\n",
    "                    })\n",
    "                    \n",
    "                ], style={'width': '33%'}),\n",
    "               \n",
    "            ], style={\n",
    "                'display': 'flex',\n",
    "                'justifyContent': 'space-between',\n",
    "                'marginTop': 20,\n",
    "                'borderRadius': 10,\n",
    "                'overflow': 'hidden'\n",
    "            })\n",
    "        ], style={\n",
    "            'width': '100%',\n",
    "            'padding': 10,\n",
    "            'backgroundColor': 'white',\n",
    "            'borderRadius': 10,\n",
    "            'marginTop': 20\n",
    "        }),\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.H4(\"Sentiment Score\"),\n",
    "                dcc.Graph(id='sentiment-gauge')\n",
    "            ], style={'width': '50%', 'padding': 10}),\n",
    "            \n",
    "            html.Div([\n",
    "                html.H4(\"Polarity & Subjectivity\"),\n",
    "                dcc.Graph(id='polarity-subjectivity')\n",
    "            ], style={'width': '50%', 'padding': 10})\n",
    "        ], style={'display': 'flex'}), \n",
    "    ], style=block_style),\n",
    "        \n",
    "    #Parts of Speech\n",
    "    html.Div([\n",
    "        html.H3(\"Parts of Speech Distribution\", style={'textAlign': 'center'}),\n",
    "        dcc.Graph(id='pos-chart')\n",
    "    ], style=block_style),\n",
    "    \n",
    "    #Sentence Analysis\n",
    "    html.Div([\n",
    "        html.H3(\"Sentence Analysis\", style={'textAlign': 'center'}),\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.H4(\"Sentence Length Distribution\"),\n",
    "                dcc.Graph(id='sentence-length')\n",
    "            ], style={'width': '50%', 'padding': 10}),\n",
    "            html.Div([\n",
    "                html.H4(\"Level of Complexity\"),\n",
    "                dcc.Graph(id='complexity-chart')\n",
    "            ], style={'width': '50%', 'padding': 10})\n",
    "        ], style={'display': 'flex'})\n",
    "    ], style=block_style)\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    [Output('summary-stats', 'children'),\n",
    "     Output('word-freq-chart', 'figure'),\n",
    "     Output('wordcloud-image', 'src'),\n",
    "     Output('sentiment-gauge', 'figure'),\n",
    "     Output('polarity-subjectivity', 'figure'),\n",
    "     Output('pos-chart', 'figure'),\n",
    "     Output('sentence-length', 'figure'),\n",
    "     Output('complexity-chart', 'figure'),\n",
    "     Output('negative-percent', 'children'),\n",
    "     Output('neutral-percent', 'children'),\n",
    "     Output('positive-percent', 'children')],\n",
    "    [Input('analyze-button', 'n_clicks')],\n",
    "    [State('text-input', 'value')]\n",
    ")\n",
    "\n",
    "def analyze_text(n_clicks, text):\n",
    "    if not text:\n",
    "        return [\"No text to analyze\"], {}, None, {}, {}, {}, {}, {} \n",
    "    \n",
    "    #Basic text cleaning\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())   \n",
    "    #Tokenization\n",
    "    words = word_tokenize(text)\n",
    "    sentences = [s.strip() for s in text.split('\\n') if s.strip()]  \n",
    "    #Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word not in stop_words and len(word) > 1]\n",
    "    #Word frequency\n",
    "    word_freq = FreqDist(filtered_words)\n",
    "    top_words = word_freq.most_common(15)  \n",
    "    #Parts of speech tagging\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    pos_counts = Counter([tag for word, tag in pos_tags])\n",
    "    #Sentiment analysis with TextBlob\n",
    "    blob = TextBlob(text)\n",
    "    # import pdb;pdb.set_trace()\n",
    "    sentiment = blob.sentiment\n",
    "\n",
    "    sent_lengths = [len(word_tokenize(sentence)) for sentence in sentences] \n",
    "\n",
    "    avg_word_length = sum(len(word) for word in filtered_words) / len(filtered_words) if filtered_words else 0\n",
    "\n",
    "    sentiment_score = sentiment.polarity\n",
    "    \n",
    "    # Sentiment percentage calculation\n",
    "    def calculate_sentiment_percentages(sentiment_score):\n",
    "        positive = 0\n",
    "        neutral = 0\n",
    "        negative = 0\n",
    "        if sentiment_score > 1e-2:\n",
    "            positive = round(sentiment_score * 100, 2)\n",
    "            neutral = 100 - (positive + negative)\n",
    "        if sentiment_score < -1e-2:\n",
    "            negative = round(abs(sentiment_score) * 100, 2)\n",
    "            neutral = 100 - (positive + negative)\n",
    "        if sentiment_score >= -1e-2 and sentiment_score <= 1e-2:\n",
    "            neutral = 100 - (positive + negative)\n",
    "\n",
    "        return positive, neutral, negative\n",
    "\n",
    "    positive_pct, neutral_pct, negative_pct = calculate_sentiment_percentages(sentiment_score)\n",
    "    \n",
    "    #Create summary statistics cards\n",
    "    summary_stats = [\n",
    "        html.Div([\n",
    "            html.H4(f\"{len(words)}\"),\n",
    "            html.P(\"Words\")\n",
    "        ], style={'textAlign': 'center', 'padding': '10px', 'backgroundColor': '#e3f2fd', 'borderRadius': '5px', 'margin': '5px', 'width': '120px'}),\n",
    "        \n",
    "        html.Div([\n",
    "            html.H4(f\"{len(sentences)}\"),\n",
    "            html.P(\"Sentences\")\n",
    "        ], style={'textAlign': 'center', 'padding': '10px', 'backgroundColor': '#e8f5e9', 'borderRadius': '5px', 'margin': '5px', 'width': '120px'}),\n",
    "        \n",
    "        html.Div([\n",
    "            html.H4(f\"{len(set(words))}\"),\n",
    "            html.P(\"Unique Words\")\n",
    "        ], style={'textAlign': 'center', 'padding': '10px', 'backgroundColor': '#fff3e0', 'borderRadius': '5px', 'margin': '5px', 'width': '120px'}),\n",
    "        \n",
    "        html.Div([\n",
    "            html.H4(f\"{round(sum(sent_lengths)/len(sentences), 1)}\"),\n",
    "            html.P(\"Avg Sentence Length\")\n",
    "        ], style={'textAlign': 'center', 'padding': '10px', 'backgroundColor': '#f3e5f5', 'borderRadius': '5px', 'margin': '5px', 'width': '120px'}),\n",
    "        \n",
    "        html.Div([\n",
    "            html.H4(f\"{round(avg_word_length, 1)}\"),\n",
    "            html.P(\"Avg Word Length\")\n",
    "        ], style={'textAlign': 'center', 'padding': '10px', 'backgroundColor': '#e0f7fa', 'borderRadius': '5px', 'margin': '5px', 'width': '120px'})\n",
    "    ]\n",
    "    \n",
    "     # Create word frequency chart\n",
    "    word_freq_df = pd.DataFrame(top_words, columns=['Word', 'Frequency'])\n",
    "    word_freq_fig = px.bar(\n",
    "        word_freq_df, \n",
    "        x='Frequency', \n",
    "        y='Word',\n",
    "        orientation='h',\n",
    "        title='Top 15 Words by Frequency',\n",
    "        color='Frequency',\n",
    "        color_continuous_scale=['lightpink', 'hotpink', 'maroon']\n",
    "    )\n",
    "    word_freq_fig.update_layout(yaxis={'categoryorder': 'total ascending'})\n",
    "    \n",
    "    # Create WordCloud\n",
    "    wordcloud = WordCloud(width=600, height=700, background_color='white', colormap='Reds').generate_from_frequencies(dict(word_freq))\n",
    "    \n",
    "    # Convert wordcloud to image\n",
    "    img = BytesIO()\n",
    "    plt.figure(figsize=(6, 7))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(img, format='png')\n",
    "    plt.close()\n",
    "    img.seek(0)\n",
    "    wordcloud_src = f'data:image/png;base64,{base64.b64encode(img.getvalue()).decode()}'\n",
    "    \n",
    "    # Create sentiment gauge\n",
    "    sentiment_fig = go.Figure(go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=sentiment.polarity,\n",
    "        title={'text': \"Sentiment Polarity\"},\n",
    "        gauge={\n",
    "            'axis': {'range': [-1, 1]},\n",
    "            'bar': {'color': \"darkblue\"},\n",
    "            'steps': [\n",
    "                {'range': [-1, -0.5], 'color': \"mediumpurple\"},\n",
    "                {'range': [-0.5, 0], 'color': \"thistle\"},\n",
    "                {'range': [0, 0.5], 'color': \"peachpuff\"},\n",
    "                {'range': [0.5, 1], 'color': \"sandybrown\"}\n",
    "            ],\n",
    "        }\n",
    "    ))\n",
    "    \n",
    "    # Create polarity vs subjectivity chart\n",
    "    polarity_subj_fig = go.Figure()\n",
    "    polarity_subj_fig.add_trace(go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=1,\n",
    "            color='white'\n",
    "        ),\n",
    "        showlegend=False\n",
    "    ))\n",
    "    polarity_subj_fig.add_trace(go.Scatter(\n",
    "        x=[sentiment.subjectivity],\n",
    "        y=[sentiment.polarity],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=20,\n",
    "            color='blue'\n",
    "        ),\n",
    "        name='Current Text'\n",
    "    ))\n",
    "    polarity_subj_fig.update_layout(\n",
    "        title='Polarity vs Subjectivity',\n",
    "        xaxis_title='Subjectivity (0=Objective, 1=Subjective)',\n",
    "        yaxis_title='Polarity (-1=Negative, 1=Positive)',\n",
    "        xaxis=dict(range=[0, 1]),\n",
    "        yaxis=dict(range=[-1, 1])\n",
    "    )\n",
    "    \n",
    "    # Create parts of speech chart\n",
    "    pos_mapping = {\n",
    "        'NN': 'Noun', 'NNS': 'Noun', 'NNP': 'Proper Noun', 'NNPS': 'Proper Noun',\n",
    "        'VB': 'Verb', 'VBD': 'Verb', 'VBG': 'Verb', 'VBN': 'Verb', 'VBP': 'Verb', 'VBZ': 'Verb',\n",
    "        'JJ': 'Adjective', 'JJR': 'Adjective', 'JJS': 'Adjective',\n",
    "        'RB': 'Adverb', 'RBR': 'Adverb', 'RBS': 'Adverb',\n",
    "        'DT': 'Determiner', 'IN': 'Preposition', 'CC': 'Conjunction'\n",
    "    }\n",
    "    \n",
    "    pos_simplified = {}\n",
    "    for tag, count in pos_counts.items():\n",
    "        category = pos_mapping.get(tag, 'Other')\n",
    "        pos_simplified[category] = pos_simplified.get(category, 0) + count\n",
    "    \n",
    "    pos_df = pd.DataFrame(list(pos_simplified.items()), columns=['POS', 'Count'])\n",
    "    pos_df = pos_df.sort_values('Count', ascending=False).head(10)\n",
    "    \n",
    "    pos_fig = px.pie(\n",
    "        pos_df, \n",
    "        values='Count', \n",
    "        names='POS', \n",
    "        title='Parts of Speech Distribution',\n",
    "        color_discrete_sequence=px.colors.qualitative.Pastel\n",
    "    )\n",
    "    pos_fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "    \n",
    "    # Create sentence length distribution\n",
    "    sent_length_fig = px.histogram(\n",
    "        x=sent_lengths,\n",
    "        nbins=20,\n",
    "        title='Sentence Length Distribution',\n",
    "        labels={'x': 'Words per Sentence', 'y': 'Frequency'},\n",
    "        color_discrete_sequence=['lightblue']\n",
    "    )\n",
    "    sent_length_fig.update_traces(marker=dict(line=dict(color='lightgray', width=1)))\n",
    "    \n",
    "    # Create complexity analysis chart\n",
    "    # Using Flesch Reading Ease score approximation\n",
    "    # Higher score = easier to read (0-100 scale)\n",
    "    word_count = len(words)\n",
    "    sentence_count = len(sentences)\n",
    "    syllable_count = sum(len(re.findall(r'[aeiouy]+', word, re.I)) for word in words)\n",
    "    \n",
    "    if sentence_count > 0 and word_count > 0:\n",
    "        flesch_score = 206.835 - 1.015 * (word_count / sentence_count) - 84.6 * (syllable_count / word_count)\n",
    "        flesch_score = max(0, min(100, flesch_score))  # Clamp between 0-100\n",
    "    else:\n",
    "        flesch_score = 50  # Default value\n",
    "        \n",
    "    complexity_categories = ['Very Easy', 'Easy', 'Fairly Easy', 'Standard', 'Fairly Difficult', 'Difficult', 'Very Difficult']\n",
    "    complexity_ranges = [90, 80, 70, 60, 50, 30, 0]\n",
    "    \n",
    "    # Find the appropriate category\n",
    "    category_index = next((i for i, score in enumerate(complexity_ranges) if flesch_score >= score), len(complexity_ranges) - 1)\n",
    "    category = complexity_categories[category_index]\n",
    "    \n",
    "    complexity_fig = go.Figure(go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=flesch_score,\n",
    "        title={'text': f\"Reading Ease: {category}\"},\n",
    "        gauge={\n",
    "            'axis': {'range': [0, 100]},\n",
    "            'bar': {'color': \"darkblue\"},\n",
    "            'steps': [\n",
    "    {'range': [0, 30], 'color': \"mediumpurple\"},  # Light Purple\n",
    "    {'range': [30, 50], 'color': \"plum\"},         # Soft Purple-Pink\n",
    "    {'range': [50, 70], 'color': \"khaki\"},        # Soft Yellow\n",
    "    {'range': [70, 90], 'color': \"peachpuff\"},    # Light Orange\n",
    "    {'range': [90, 100], 'color': \"sandybrown\"}   # Warm Medium-Light Orange\n",
    "        ]\n",
    "        }\n",
    "    ))\n",
    "    return (summary_stats, word_freq_fig, wordcloud_src, \n",
    "            sentiment_fig, polarity_subj_fig, pos_fig, \n",
    "            sent_length_fig, complexity_fig,\n",
    "            f\"{negative_pct}%\", \n",
    "            f\"{neutral_pct}%\",  \n",
    "            f\"{positive_pct}%\")\n",
    "\n",
    "@app.callback(\n",
    "    Output('text-input', 'value'),\n",
    "    Input('upload-data', 'contents'),\n",
    "    State('upload-data', 'filename')\n",
    ")\n",
    "def update_textarea(contents, filename):\n",
    "    if contents is not None:\n",
    "        content_type, content_string = contents.split(',')\n",
    "        decoded = base64.b64decode(content_string).decode('utf-8')\n",
    "        return decoded\n",
    "    return ''\n",
    "\n",
    "#file callback\n",
    "@app.callback(\n",
    "    Output(\"download-text\", \"data\"),\n",
    "    Input(\"download-button\", \"n_clicks\"),\n",
    "    State(\"text-input\", \"value\"),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def download_text(n_clicks, text):\n",
    "    if text:\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        return dict(content=text, filename=f\"text_analysis_{timestamp}.txt\")\n",
    "    return None\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3773f2a-c5a8-4916-98ff-3410e33e4b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a3849b0-26d4-4848-b92b-fcf1cd71d6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/anniewu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>30</td>\n",
       "      <td>42.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>23</td>\n",
       "      <td>32.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>18</td>\n",
       "      <td>25.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Total  Percentage\n",
       "sentiment                   \n",
       "positive      30       42.25\n",
       "negative      23       32.39\n",
       "neutral       18       25.35"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('chapter_45 16.58.50.txt', 'r', encoding='utf-8') as chap45:\n",
    "    lines = chap45.readlines()\n",
    "\n",
    "# Remove newline characters and create a DataFrame\n",
    "lines = [line.strip() for line in lines]\n",
    "df = pd.DataFrame(lines, columns=['Sentence'])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('chap45.csv', index=False)\n",
    "csv_45 = \"chap45.csv\"\n",
    "chap45_data = pd.read_csv(csv_45)\n",
    "\n",
    "chap45_data[['polarity','subjectivity']] = chap45_data['Sentence'].apply(lambda Text : pd.Series(TextBlob(Text).sentiment))\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "for index, row in chap45_data['Sentence'].items():\n",
    "    # compute a score\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    # Assign score categories to variables\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    \n",
    "    # If negative score (neg) is greater than positive score (pos), then the text should be categorized as \"negative\"\n",
    "    if neg> pos:\n",
    "        chap45_data.loc[index,\"sentiment\"] = 'negative'\n",
    "    # If positive score (pos) is greater than the negative score (neg), then the text should be categorized as \"positive\"\n",
    "    elif pos > neg:\n",
    "        chap45_data.loc[index,\"sentiment\"] = \"positive\"\n",
    "    # Otherwise \n",
    "    else:\n",
    "        chap45_data.loc[index,\"sentiment\"] = \"neutral\"\n",
    "        chap45_data.loc[index,'neg'] = neg\n",
    "        chap45_data.loc[index,'pos'] = pos\n",
    "        chap45_data.loc[index,'neu'] = neu\n",
    "        chap45_data.loc[index,'compound'] = comp\n",
    "\n",
    "# Let's take a look at how many are labelled positive, negative or neutral\n",
    "chap45_negative = chap45_data[chap45_data['sentiment']=='negative']\n",
    "chap45_positive = chap45_data[chap45_data['sentiment']=='positive']\n",
    "chap45_neutral = chap45_data[chap45_data['sentiment']=='neutral']\n",
    "\n",
    "# Let's count how many of these values belong to each category. We will define a function to count values.\n",
    "def count_values_in_column(data,feature):\n",
    "    \n",
    "    total = data.loc[:,feature].value_counts(dropna=False)\n",
    "    percentage = round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
    "    \n",
    "    return pd.concat([total,percentage],axis=1, keys=['Total', 'Percentage'])\n",
    "\n",
    "# Values for sentiment\n",
    "pc = count_values_in_column(chap45_data, \"sentiment\")\n",
    "\n",
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4220b0-e0a9-4394-937b-53405046f67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
